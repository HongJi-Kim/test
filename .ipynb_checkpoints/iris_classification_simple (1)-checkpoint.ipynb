{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b7da92-440a-47a3-8090-e081ba80736d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "#00DE62",
     "id": "ab2d95a2-220f-4f7d-8c1a-ef03b514587e",
     "isComponent": true,
     "name": "Read data",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([1,2,3])\n",
    "df123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8a6214-5342-4205-8214-b86bbbf890f3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "f673cd87-389e-4706-962e-c5de6699a756",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([1,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c998fa8-4731-4ffb-b6f8-2d389c4e8c82",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "ecb7141a-ce5c-4fc3-be3b-f42abe7d3642",
     "isComponent": true,
     "name": "Data loader",
     "parents": [
      {
       "id": "ab2d95a2-220f-4f7d-8c1a-ef03b514587e",
       "name": "Read data"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __pdc_data_loader__(  # type: ignore\n",
    "    input_df: str,\n",
    "    ratio: float,\n",
    "    batch_size: int,\n",
    "    batch_shuffle: bool,\n",
    "    tv_shuffle: bool,\n",
    "    drop_last: bool,\n",
    "    target: list,  # type: ignore\n",
    "):\n",
    "    \"\"\"read data from database\"\"\"\n",
    "    import random\n",
    "    from typing import Any, Optional, Tuple\n",
    "\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "    class SampleDataset(Dataset):  # pylint: disable=missing-class-docstring\n",
    "        def __init__(self, data: pd.DataFrame, target: Optional[pd.DataFrame] = None) -> None:\n",
    "            super().__init__()\n",
    "            self.data = torch.from_numpy(data.values)\n",
    "            if target is not None:\n",
    "                self.target = torch.from_numpy(target.values)\n",
    "                if target.shape[-1] == 1:\n",
    "                    self.target = torch.from_numpy(target.values.squeeze())\n",
    "                else:\n",
    "                    self.target = torch.from_numpy(target.values)\n",
    "            else:\n",
    "                self.target = target\n",
    "\n",
    "        def __len__(self) -> int:\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx: int) -> Any:\n",
    "            if self.target is not None:\n",
    "                return self.data[idx], self.target[idx]\n",
    "            return self.data[idx]\n",
    "\n",
    "    # pylint: disable=missing-function-docstring\n",
    "    def split(\n",
    "        data: pd.DataFrame, ratio: float, target: Optional[pd.DataFrame] = None, shuffle: bool = False\n",
    "    ) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "\n",
    "        data_cnt = int(data.shape[0] * ratio)\n",
    "\n",
    "        indices = list(data.index)\n",
    "        if shuffle:\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        if target is not None:\n",
    "            return (\n",
    "                (\n",
    "                    pd.DataFrame(data, index=indices[:data_cnt]),\n",
    "                    pd.DataFrame(target, index=indices[:data_cnt]),\n",
    "                ),\n",
    "                (\n",
    "                    pd.DataFrame(data, index=indices[data_cnt:]),\n",
    "                    pd.DataFrame(target, index=indices[data_cnt:]),\n",
    "                ),\n",
    "            )\n",
    "        return (\n",
    "            (\n",
    "                pd.DataFrame(data, index=indices[:data_cnt]),\n",
    "                None,\n",
    "            ),\n",
    "            (\n",
    "                pd.DataFrame(data, index=indices[data_cnt:]),\n",
    "                None,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    data: pd.DataFrame = input_df\n",
    "    train_loader, valid_loader = None, None\n",
    "    if target:\n",
    "        data_df = pd.DataFrame(data, columns=[x for x in data.columns if x not in target])\n",
    "        target_df = pd.DataFrame(data, columns=target)\n",
    "        train, valid = split(data_df, ratio, target_df, tv_shuffle)\n",
    "        if train[0].shape[0] > 0:\n",
    "            train_loader = DataLoader(\n",
    "                dataset=SampleDataset(data=train[0], target=train[1]),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=batch_shuffle,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "        if valid[0].shape[0] > 0:\n",
    "            valid_loader = DataLoader(\n",
    "                dataset=SampleDataset(data=valid[0], target=valid[1]),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=batch_shuffle,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "    else:\n",
    "        train, valid = split(data, ratio, shuffle=tv_shuffle)\n",
    "        if train[0].shape[0] > 0:\n",
    "            train_loader = DataLoader(\n",
    "                dataset=SampleDataset(data=train[0]),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=batch_shuffle,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "        if valid[0].shape[0] > 0:\n",
    "            valid_loader = DataLoader(\n",
    "                dataset=SampleDataset(data=valid[0]),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=batch_shuffle,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "train, valid = __pdc_data_loader__(\n",
    "    input_df=df,\n",
    "    ratio=0.8,\n",
    "    batch_size=4,\n",
    "    batch_shuffle=True,\n",
    "    tv_shuffle=True,\n",
    "    drop_last=True,\n",
    "    target=['class'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3195db8-81d4-4058-9419-ca23355229b9",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "0b224f6b-a1c3-4235-9e25-be52f638606f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc658c7-d856-427b-82f5-b54247113e09",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "62535059-9784-42d0-9799-29d5c99f3472",
     "isComponent": true,
     "name": "Modeling",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F  \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, 3)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "model = Model(4).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606a1ba7-c4c2-402d-9bb5-69cdca6afa14",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "1a49b14c-abaf-4f75-b146-e43813e2e4fb",
     "isComponent": true,
     "name": "Training",
     "parents": [
      {
       "id": "62535059-9784-42d0-9799-29d5c99f3472",
       "name": "Modeling"
      },
      {
       "id": "ecb7141a-ce5c-4fc3-be3b-f42abe7d3642",
       "name": "Data loader"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __pdc_trainer__(  # type: ignore # noqa: C901\n",
    "    is_classification: int,\n",
    "    train_loader,  # DataLoader\n",
    "    valid_loader,  # DataLoader\n",
    "    train_metric_members,  # List[str]\n",
    "    valid_metric_members,  # List[str]\n",
    "    monitoring: str,\n",
    "    early_stopping_mode: str,\n",
    "    model,  # nn.Module\n",
    "    loss_impl,  # nn.Module\n",
    "    optimizer_impl,  # nn.optim\n",
    "    learning_rate: float,\n",
    "    n_epochs: int,\n",
    "):\n",
    "    from collections import defaultdict\n",
    "    from typing import Any, DefaultDict, Dict, List, Optional, Tuple\n",
    "\n",
    "    import pytorch_lightning as pl\n",
    "    import torch\n",
    "    import torchmetrics\n",
    "    from livelossplot import PlotLosses\n",
    "    from pytorch_lightning.callbacks import EarlyStopping\n",
    "    from pytorch_lightning.loggers import LightningLoggerBase\n",
    "    from pytorch_lightning.utilities.distributed import rank_zero_only\n",
    "    from torch import nn\n",
    "    from torch.optim import Optimizer\n",
    "\n",
    "    class CanvasTrainerLightningLogger(LightningLoggerBase):\n",
    "        \"\"\"Canvas Trainer Logger\"\"\"\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            super().__init__()\n",
    "            self.metric_history: DefaultDict[str, List[Any]] = defaultdict(list)\n",
    "            self.live_metric = PlotLosses()\n",
    "\n",
    "        @property\n",
    "        def experiment(self) -> None:\n",
    "            pass\n",
    "\n",
    "        @property\n",
    "        def name(self) -> str:\n",
    "            return \"CanvasTrainerLogger\"\n",
    "\n",
    "        @property\n",
    "        def version(self) -> str:\n",
    "            return \"mvp\"\n",
    "\n",
    "        @rank_zero_only\n",
    "        def log_hyperparams(self, params: Any) -> None:  # pylint: disable=arguments-differ\n",
    "            pass\n",
    "\n",
    "        @rank_zero_only\n",
    "        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:\n",
    "            del metrics[\"epoch\"]\n",
    "\n",
    "            if not metrics.keys():\n",
    "                return\n",
    "\n",
    "            is_valid = list(metrics.keys())[-1][:4] == \"val_\"\n",
    "\n",
    "            if is_valid:\n",
    "                self.metric_history[\"val\"].append(metrics)\n",
    "            else:\n",
    "                self.metric_history[\"train\"].append(metrics)\n",
    "                self.live_metric.update({**self.metric_history[\"train\"][-1], **self.metric_history[\"val\"][-1]})\n",
    "                self.live_metric.send()\n",
    "\n",
    "    class LitModule(pl.LightningModule):  # pylint: disable=too-many-ancestors, missing-class-docstring\n",
    "        def __init__(  # pylint: disable=too-many-arguments\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            loss_impl: nn.Module,\n",
    "            optimizer_impl: Optimizer,\n",
    "            learning_rate: float,\n",
    "            metric_members: Dict[str, Any],\n",
    "            is_classification: int,\n",
    "        ) -> None:\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "\n",
    "            self.loss_func = loss_impl()\n",
    "            self.optimizer_impl = optimizer_impl\n",
    "            self.learning_rate = learning_rate\n",
    "\n",
    "            self.metric_members = metric_members\n",
    "\n",
    "            for mode in [\"train\", \"val\"]:\n",
    "                auroc_metric_attr = (mode + \"_\" if mode != \"train\" else \"\") + \"auroc\"\n",
    "                setattr(self, auroc_metric_attr, self.metric_members[mode].get(\"AUROC\"))\n",
    "\n",
    "            self._is_classification = is_classification\n",
    "\n",
    "        # pylint: disable=invalid-name\n",
    "        def _calculate_log_metric(self, y_hat: torch.Tensor, y: torch.Tensor, is_valid: bool = False) -> None:\n",
    "            \"\"\"calculate log metric with metric members\"\"\"\n",
    "            metric_members, prefix = None, \"\"\n",
    "            if is_valid:\n",
    "                metric_members = self.metric_members[\"val\"]\n",
    "                prefix += \"val_\"\n",
    "            else:\n",
    "                metric_members = self.metric_members[\"train\"]\n",
    "\n",
    "            for metric_member_str, metric_impl in metric_members.items():\n",
    "                if metric_member_str == \"AUROC\":\n",
    "                    getattr(self, prefix + \"auroc\")(y_hat.detach(), y.detach())\n",
    "                    try:\n",
    "                        self.log(\n",
    "                            prefix + metric_member_str, getattr(self, prefix + \"auroc\"), on_step=False, on_epoch=True\n",
    "                        )\n",
    "                    except ValueError():  # type: ignore\n",
    "                        pass\n",
    "\n",
    "                else:\n",
    "                    metric = metric_impl(y_hat, y)\n",
    "                    self.log(prefix + metric_member_str, metric, on_step=False, on_epoch=True)\n",
    "\n",
    "        # pylint: disable=arguments-differ\n",
    "        def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], _: Any) -> torch.Tensor:\n",
    "            return self._step_func(batch, is_valid=False)\n",
    "\n",
    "        # pylint: disable=arguments-differ\n",
    "        def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], _: Any) -> torch.Tensor:\n",
    "            return self._step_func(batch, is_valid=True)\n",
    "\n",
    "        def _step_func(self, batch: Tuple[torch.Tensor, torch.Tensor], is_valid: bool = False) -> torch.Tensor:\n",
    "            x, y = batch  # pylint: disable=invalid-name\n",
    "            if self._is_classification:\n",
    "                y = y.long()  # pylint: disable=invalid-name\n",
    "            y_hat = self.model(x)\n",
    "\n",
    "            loss = self.loss_func(y_hat, y)\n",
    "            self._calculate_log_metric(y_hat, y, is_valid=is_valid)\n",
    "            return loss\n",
    "\n",
    "        def configure_optimizers(self) -> Optimizer:\n",
    "            return self.optimizer_impl(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def load_metric_impl(members: List[str], num_classes: Optional[int] = None) -> Optimizer:\n",
    "        \"\"\"load metric implementation on torch.nn or torchmetrics with their names\"\"\"\n",
    "        metric_impls = {}\n",
    "        for member_str in members:\n",
    "            if member_str == \"AUROC\":\n",
    "                metric_impls[member_str] = getattr(torchmetrics, member_str)(\n",
    "                    num_classes=num_classes, compute_on_step=False\n",
    "                )\n",
    "\n",
    "            elif member_str in [\"CrossEntropyLoss\", \"MSELoss\", \"L1Loss\"]:\n",
    "                metric_impls[member_str] = getattr(nn, member_str)()\n",
    "\n",
    "            elif member_str in [\"Accuracy\", \"AUROC\", \"R2Score\"]:\n",
    "                metric_impls[member_str] = getattr(torchmetrics, member_str)()\n",
    "        return metric_impls\n",
    "\n",
    "    # trainer main\n",
    "    n_classes = None\n",
    "    if is_classification:\n",
    "        labels = torch.cat([y for _, y in valid_loader])\n",
    "        if len(labels.unique()) > 2:\n",
    "            n_classes = len(labels.unique())\n",
    "\n",
    "    metric_members = dict(\n",
    "        train=load_metric_impl(train_metric_members, num_classes=n_classes),\n",
    "        val=load_metric_impl(valid_metric_members, num_classes=n_classes),\n",
    "    )\n",
    "\n",
    "    canvas_trainer_logger = CanvasTrainerLightningLogger()\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"val_\" + monitoring, mode=early_stopping_mode)\n",
    "    lit = LitModule(\n",
    "        model=model,\n",
    "        loss_impl=loss_impl,\n",
    "        optimizer_impl=optimizer_impl,\n",
    "        learning_rate=learning_rate,\n",
    "        metric_members=metric_members,\n",
    "        is_classification=is_classification,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=n_epochs,\n",
    "        logger=canvas_trainer_logger,\n",
    "        callbacks=[early_stopping_callback],\n",
    "        checkpoint_callback=False,\n",
    "    )\n",
    "    trainer.fit(lit, train_loader, valid_loader)\n",
    "    return (canvas_trainer_logger.metric_history, model, model)\n",
    "\n",
    "import torch\n",
    "c, b, a = __pdc_trainer__(\n",
    "    is_classification=1,\n",
    "    train_loader=train,\n",
    "    valid_loader=valid,\n",
    "    train_metric_members=['CrossEntropyLoss'],\n",
    "    valid_metric_members=['CrossEntropyLoss'],\n",
    "    monitoring='CrossEntropyLoss',\n",
    "    early_stopping_mode='min',\n",
    "    model=model,\n",
    "    loss_impl=torch.nn.CrossEntropyLoss,\n",
    "    optimizer_impl=torch.optim.Adam,\n",
    "    learning_rate=learning_rate,\n",
    "    n_epochs=n_epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d6e66-00c2-4088-ab13-4d69a84ef34c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "84484d20-2bd6-472d-91a1-a9c10d1bb17d",
     "isComponent": true,
     "name": "new component",
     "parents": [
      {
       "id": "1a49b14c-abaf-4f75-b146-e43813e2e4fb",
       "name": "Training"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([1,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5554d4-abef-44dc-9990-943b7854953f",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "9dbcb0cb-255c-4aca-95d0-4aaa1e199b07",
     "isComponent": true,
     "name": "new component_2",
     "parents": [
      {
       "id": "84484d20-2bd6-472d-91a1-a9c10d1bb17d",
       "name": "new component"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([1,2,3])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "parameters": [
    {
     "name": "n_epochs",
     "type": "int",
     "value": "10"
    },
    {
     "name": "learning_rate",
     "type": "float",
     "value": "0.001"
    }
   ],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
