[2022-05-20 14:47:39] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='[{"name":"a","type":"int","value":"12"}]\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20username-localhost-8888=2%7C1:0%7C10:1653025658%7C23:username-localhost-8888%7C44:NGU3Y2ZmMTRjYTYzNDkyOWExNmY1MjViODQyOWZjNTk=%7Ccee9b2712bd5137b544ef3d648847fcdcb4a25430baf4a9fa078639ad99e932a', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253', no_reply=True)
[2022-05-20 14:47:39] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20username-localhost-8888=2%7C1:0%7C10:1653025659%7C23:username-localhost-8888%7C44:OGM3NWU1ODM0YjBmNDkzNzhlNmE1ZGI0NmVkYWVkYWY=%7C014259efa9e92d222c7ebec76b79139815c4e9cc132df082cd9a527288f59a12', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:47:39] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:47:42] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025661%7C23:username-localhost-8888%7C44:YzNhNTk5ZDcwMjdlNDI5YTliYTllNmRkNjAwNGYzNWY=%7C347afe856041f706f4ab238cf984ff65b99dfd8f9e6b36a07e682aab714114f4', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:47:42] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:47:43] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 123456 (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 123 (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:47:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025675%7C23:username-localhost-8888%7C44:NWRjNTk1MjVkNzllNDc5NzlhNTJiNGM3ZjllNWIwZWQ=%7Ccf229e09a9c35a63f2696286465a0d90713e467b7bb7511769917aab0e1ddb6e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:47:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:08] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025687%7C23:username-localhost-8888%7C44:ZTFmYTdiYjVhNTVlNGMyM2FmMzBkNzMyN2RiMDQ2MTU=%7C2a9ac291d4f30e10e5591e1cdb485d7b6361fcd19352cfe5e7cfc67ce0edc50e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:08] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:11] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"Load iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025691%7C23:username-localhost-8888%7C44:NjgyZDg0MTU5ZWZmNDQxNjg5Y2EzZGIyMDBlZDg1YzY=%7C55ad88b55abd79e05e3575614625b8869a783d5fd1c687c9c00e56d07b12c4f1', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:11] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'Load iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:11] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 123 (eef2dc4b-fb13-419b-a5af-f0031467c624) -> Load iris data (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:48:13] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"Load iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025692%7C23:username-localhost-8888%7C44:YzQ1ZGUzN2Y5NjJmNGYyZThjYWE3MmNiMWE5ZDE4ZjY=%7C2a57a4d2423e6b9438f86a319a76606b394a9e26639f05431459d161c53ef6f8', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:13] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'Load iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:14] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"Load iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025660.0;%20username-localhost-8888=2%7C1:0%7C10:1653025693%7C23:username-localhost-8888%7C44:YTMwMDQ3NTAxNjlhNGI0NjkxOTUzZjBlNzc2NWY4ZjY=%7C6523b0eaf54b04e0d1dd35c2f182cefec00dc07b2be5da9475f07b36a30a196a', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:14] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'Load iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025698.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20username-localhost-8888=2%7C1:0%7C10:1653025697%7C23:username-localhost-8888%7C44:M2NmODcxYjdmY2YyNGQ2YWJkNzRlZTMwZjdlOTU2YmY=%7C62c42116bcf586b31d069014769710df95e8c6cd18f160cd2e73567da4be88f0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025698.0', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:20] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:20] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component Load iris data (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 123 (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:48:56] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025734.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025734.0;%20username-localhost-8888=2%7C1:0%7C10:1653025736%7C23:username-localhost-8888%7C44:YjYzYTVjMmY2YjkwNDg3NWE1YWUwYzU3ZTNkN2YzYmY=%7Cc07f6fd94ddab85a9d5f509ac255ccfa0b40bd46d1bc86a7cfc6f3c9144abf41', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:48:56] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:48:56] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 123 (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:49:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025737.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025737.0;%20username-localhost-8888=2%7C1:0%7C10:1653025740%7C23:username-localhost-8888%7C44:ODY2MjhkY2FkNzg2NDE3ZTkyNGZiNGJhMTg2ZDM2YWI=%7C336a49f2741c1c85bb79463564acd935a6d550d6d8aa0af35b2872258f2cb567', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:49:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:49:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025781%7C23:username-localhost-8888%7C44:MmU0MzAwY2YyZTg0NDc4MjgwNjQ2MDg3YWIxYTFiNDg=%7Cbac92d9dbc3a5b490ff5af4c3a200b1d657187addba7f1475662f22a329fbd6b', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:49:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:49:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025784%7C23:username-localhost-8888%7C44:OTg2Nzg5Y2NmNjE2NDhhN2E0OGMzODUwODA3YWMzN2I=%7C60db66e1c235781be5bf24392257a7089911774245b66337fc44117eb7a58aa0', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:49:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:50:22] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025820%7C23:username-localhost-8888%7C44:NjI3NzY3OTY4NWQ3NDJjNjg4MDkyZGFjZDExY2FhNmE=%7Cd3a42d332ed6bd6c7862c9b87e3eb53e3e6e684171040a26312d438ad72ccebd', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:50:22] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:50:36] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025834%7C23:username-localhost-8888%7C44:YWE1ZWNmNTVhZTZkNDI3ZWJkMzJjMmIzZDliMzc2MTE=%7Cd170ec79e17d3ed6c049269968bb6ab858e55e348ce781a14dca5d9c376ca473', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:50:36] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:50:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025843%7C23:username-localhost-8888%7C44:MzhlOGI5M2Q0OGZjNDg1ZDhlZDg2OWFkOTYzZGZjYTE=%7C96bf6174ef191837044aac19dc7cc01d1899d14380d0e7b55a5a5200c5e34fb5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:50:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:50:56] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025747.0;%20username-localhost-8888=2%7C1:0%7C10:1653025849%7C23:username-localhost-8888%7C44:MWMyMDIyYzIwYTI1NDAzYzlkN2E3MWIwNGY4MjIxNjE=%7C1843397b0bd3fe7153be74c4ab9ef03cd3797ce90f32ae27975beede443b79f3', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:50:56] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20username-localhost-8888=2%7C1:0%7C10:1653025859%7C23:username-localhost-8888%7C44:YWI3NmFiMDg3NWYxNDA1ODljNGY1OGVhYWM3ZWNkOWU=%7Cd1d92ac2d6fd850c320c192b3fbd4ed91c2c0656ca26dd4cbc4ba460930cedf4;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20username-localhost-8888=2%7C1:0%7C10:1653025866%7C23:username-localhost-8888%7C44:MGZlNzg2Mzk5MDcyNGU0ZTg5MWNlYzc1ZjI3MWVkZDU=%7Cb5576576833a13cedb31bdbd987e61da93beb9563919267973233b73c2a6b1c1', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:31] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20username-localhost-8888=2%7C1:0%7C10:1653025891%7C23:username-localhost-8888%7C44:NDIzMTcwNjZhOWEwNGE4MGJlNDAyZWRjMzUyYTM2NTc=%7C4305ddae1230b5939dbdbc9935fb81f85e18f2643428a0a425f3f1374152919e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:31] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025860.0;%20username-localhost-8888=2%7C1:0%7C10:1653025896%7C23:username-localhost-8888%7C44:NTIyNzI1YTBiMWRiNGU3N2JkMDg4MDQ0Nzg2MmY4ZmQ=%7Cd3e9bfea2d3a67b19e7c6929f0de79dbcd8bb78a7222e5ef6994e8d1ce5c4a7c', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdf\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20username-localhost-8888=2%7C1:0%7C10:1653025898%7C23:username-localhost-8888%7C44:MDJhYWNiZjlmYzA2NDg4NzlhYmI1N2Y3ZWUzNDUzMmY=%7Cecf2b2ec23ca52b4fb9f71f6c155bb29b94a92d6b0765e444ce7b536f80eee12;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdf\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:41] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025901%7C23:username-localhost-8888%7C44:NTA2Y2I3YzlkZWFiNDhlZDg1MjYzODJjOGQ1OTM3OGU=%7C8c16a5ced6da9029f8f614770cd2bd13c8f10c2950b4732206e38a9e11807641', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:41] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_irids()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025902%7C23:username-localhost-8888%7C44:YWNiNmExYmM3MWNmNGI0NmJmOWIxYWQyOThlYWU1YzA=%7Cbdd1b428d6ae82dce40f2ab555155ef186682ef552c0f0849858a712d2425ee5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:43] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_irids()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:43] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iridds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025904%7C23:username-localhost-8888%7C44:Mzc2ZWRhNjhhOTVkNDVhYzg4OTdmM2QwMTg0NTUwNjU=%7C121a9b4175901855b1754dd9091a5a5a0a2e33313a733eddd2572d768b4d744e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iridds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:44] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025904%7C23:username-localhost-8888%7C44:ZjdiODBlZmNlMTUwNGQ3ZWJiNTMzZTRiODE3OWM3Mjc=%7C5bb277f44db6a2abef8a25a849a8b488447d875dd0511b608f8dc8a7d777e661', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:44] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iridddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025904%7C23:username-localhost-8888%7C44:YjVjZTM4ZjZkMTE2NDE4NzlmZTNmN2I3YjA5MzU5ODk=%7C9177a841dce1a9829be1d9d6aea74dbbdb3aca0cd264c01a25427ab7ac8a6f3e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iridddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:44] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025904%7C23:username-localhost-8888%7C44:MTQ1YWI5YTFjMzBlNDllZjg1ZTJlZDU1N2E4MmRhZGI=%7C633c289ff4e60dcfabb94bd60a08f24e793bd2c7ead00fb49205966750c9ccfb', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:44] mrx-link.MRXLinkDag.mrxlink_update_dag() DEBUG: <12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231sdfsdafsfsad","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025904%7C23:username-localhost-8888%7C44:ZmY4MmVmODM4ODE4NDU4NjhkOTMxOGUwOTAxOGM4YTE=%7Cd6430e737d4bc788d7af652796c7d044c85e35ff6af0c117996be889b020d670', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:51:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231sdfsdafsfsad', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:51:44] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 12341231 (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 12341231sdfsdafsfsad (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:52:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231sdfsdafsfsad","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025926%7C23:username-localhost-8888%7C44:MmU1YzM2ZTEwYTRlNGExM2FjMzVjNWU2OWY1OWU1OTM=%7Ca4f93639b8a4d28799a7a6ad3b49885d7cec473f803a2985f37763e496d97ec8', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231sdfsdafsfsad', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:52:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231sdfsdafsfsad","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025929%7C23:username-localhost-8888%7C44:MGIxNWZkNDI3ZWJlNGU1NmI2YTRmZjdjNGUxZjM5NmI=%7C1444f46ef384b6adf47617f373a810d01a183ca7cf86ed781f3fb52cc1f5c5f5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231sdfsdafsfsad', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:52:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"12341231sdfsdafsfsad","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025898.0;%20username-localhost-8888=2%7C1:0%7C10:1653025936%7C23:username-localhost-8888%7C44:ZWU5YmNmN2RhNzg3NGQ1ZjhhY2NhYzhmZGUzOWUwZTE=%7Cf81ada2343b9fe7c3a467fc197ef7353cc928c6b3436afb81fd75a8246dbe5b3', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '12341231sdfsdafsfsad', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:52:24] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"new name","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20username-localhost-8888=2%7C1:0%7C10:1653025938%7C23:username-localhost-8888%7C44:MmZhOTE4MjgzNDQwNDkwZTgyMDY5ODY0NWUwMDU1YjU=%7C78dc5a1108be5f365af6c22c08827adb2e46ec4054eb74958840bf50af8e79fe;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:24] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'new name', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:52:24] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 12341231sdfsdafsfsad (eef2dc4b-fb13-419b-a5af-f0031467c624) -> new name (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:52:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"new name","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20username-localhost-8888=2%7C1:0%7C10:1653025961%7C23:username-localhost-8888%7C44:ZGYxZWJiOTk3OWM3NDM2ODgwNzhkN2JmOTZkZThiODE=%7C650694c3f0f0f4cdeb4c5e8501f1b78e626f09f2d87e9cb20b5af0140e3188d4', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'new name', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:52:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"new name","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20username-localhost-8888=2%7C1:0%7C10:1653025975%7C23:username-localhost-8888%7C44:N2RmZmZmMmVmNDM4NDc1YmE2N2I2YjU3N2QzYWNjN2Q=%7C2e105c0a571c8c80f1ace358b949321f4729f326a70fad46c0f90d19a2abfb99', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:52:55] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'new name', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:53:00] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"new name","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20username-localhost-8888=2%7C1:0%7C10:1653025979%7C23:username-localhost-8888%7C44:ZGU4Y2I0MDZhZmEwNDI4ZmFmZTU5NTJmYWUxNGYyM2M=%7C79c1641ceef763d22e44a6da14c302f9d4b80574c8eb0745566aa67e2e6b2094', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:53:00] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'new name', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:53:08] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"new name","code":"from sklearn.datasets import load_iris\\nsdfsafasdfsa\\ndata = load_iriddddds()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"eef2dc4b-fb13-419b-a5af-f0031467c624"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025940.0;%20username-localhost-8888=2%7C1:0%7C10:1653025988%7C23:username-localhost-8888%7C44:YjAxYjA3YjM0NDMyNDMzYWJjYWEwNjNhM2NjZWQ4MjU=%7C2cea93cf0c4f8651533f8f16388ef38ffa9676401dc57051c5e0fbf7850474f5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:53:08] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'new name', 'code': 'from sklearn.datasets import load_iris\nsdfsafasdfsa\ndata = load_iriddddds()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'eef2dc4b-fb13-419b-a5af-f0031467c624'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
