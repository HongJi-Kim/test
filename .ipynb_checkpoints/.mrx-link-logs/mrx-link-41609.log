[2022-06-13 19:02:32] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='[{"name":"a","type":"int","value":"12"}]\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114551%7C23:username-localhost-8889%7C44:OWM1OGRhNGI4MmY3NGNiZGE4NzIzZTQxZDRjMWI2YWE=%7Cc46eb6e1f00dc5d94a1d0b6461d535c6a46d9a17774bdc2c8953849be37dcb60', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9', no_reply=True)
[2022-06-13 19:02:32] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114551%7C23:username-localhost-8889%7C44:YzA4OTBmNmVkYzEwNDgzYWEyMzljYzY0MzRjMGE5ZWU=%7C08cd1a438a9511444ccc90b53d4987ac1ab1a4bc8e73464b9f7562c5b4ea4a1b', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:02:32] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"from sklearn.datasets import load_iris\\n\\ndata = !load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114581%7C23:username-localhost-8889%7C44:ZWUxMjk5Nzc0ZWViNDRmNGFjYjk0MzI5MzE3YjhlN2M=%7Ceb6679146fe274d862df26ac15becba8de151edb33a36554c2c6fed16dd0953a', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': 'from sklearn.datasets import load_iris\n\ndata = !load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:02] mrx-link.MRXLinkDag.add_node() DEBUG: <1234 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-06-13 19:03:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"from sklearn.datasets import load_iris\\n\\ndata = !!load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114582%7C23:username-localhost-8889%7C44:ZGRiMjMwNjI4OTFiNDQ3Yjg1MDVhZDA5MjYzN2NiMDg=%7C4ab44b2234c6b16f90fe2ffa62e6547b9d7262b5716ae002679527d0eddf2782', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': 'from sklearn.datasets import load_iris\n\ndata = !!load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:02] mrx-link.MRXLinkDag.add_node() DEBUG: <1234 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-06-13 19:03:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"from sklearn.datasets import load_iris\\n\\ndata = !!!!!load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114583%7C23:username-localhost-8889%7C44:MGQ3NDM5MzY3Mzc3NGIxOWI1MTY3MTc4N2E5ZDRmZWE=%7Cbeec681c5972d6335ad02e559a6220d8fcd47af6e8f5eebdb7a2b0b96cfc6ba3', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': 'from sklearn.datasets import load_iris\n\ndata = !!!!!load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:03] mrx-link.MRXLinkDag.add_node() DEBUG: <1234 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-06-13 19:03:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"from sklearn.datasets import load_iris\\n\\ndata = !!!!!!load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114583%7C23:username-localhost-8889%7C44:MmIwMDY1NDUwYTcyNDFmYTllNjI1Yzg5YjY4MmRkNjk=%7Ccb55ff4fc0d0007daa130d962fdbb2a41027b36febb6a1d3c104e6ef4f647597', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': 'from sklearn.datasets import load_iris\n\ndata = !!!!!!load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:03] mrx-link.MRXLinkDag.add_node() DEBUG: <1234 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-06-13 19:03:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"1234","code":"# from sklearn.datasets import load_iris\\n\\ndata = !!!!!!load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114585%7C23:username-localhost-8889%7C44:MTg2N2Q2OTA1YWRiNGE4MTk3NWU2MWExNmZkY2RhYTU=%7C5b3bb2469c1f068fc78592a4f23883326ac80255a479afaba384fb2ee569544e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:07] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '1234', 'code': '# from sklearn.datasets import load_iris\n\ndata = !!!!!!load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-13 19:03:07] mrx-link.MRXLinkDag.add_node() DEBUG: <1234 (eef2dc4b-fb13-419b-a5af-f0031467c624)>.component_type: CodeCell -> CodeCell
[2022-06-13 19:03:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20_ga=GA1.1.858313459.1651647659;%20_xsrf=2%7Cd9b93425%7Cb864037f78e720e235051f18f4b2f004%7C1655086118;%20_ga_PQWQV19ZLY=GS1.1.1655106856.5.1.1655107088.0;%20username-localhost-8889=2%7C1:0%7C10:1655114588%7C23:username-localhost-8889%7C44:ODY4NmY4ZWZhZGU1NDdjNjg1NDM4OThhYTg0NDczOTk=%7C55671cbe93e9a6d49eae9e7e62f0c933af0b603f9555253660b6ad3309f898b4', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%2080add5c51e8e1b74e94b4dc110540ec77ba79bfee95a32f9')
[2022-06-13 19:03:09] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
