[2022-06-03 09:43:28] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='[{"name":"a","type":"int","value":"12"}]\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20username-localhost-8889=2%7C1:0%7C10:1654217007%7C23:username-localhost-8889%7C44:NmRjMWEyNDRkNDNjNDNjMWJjNDlmNDFlZjNiMjJjOTE=%7C3da19b2b1f55bf1a49da4a13c837b61aed09d6bfa1adca4c851d1cc527fa21c7', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d', no_reply=True)
[2022-06-03 09:43:28] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20username-localhost-8889=2%7C1:0%7C10:1654217008%7C23:username-localhost-8889%7C44:YjI2ODNlZjkzYmEwNDhlYTg1M2IzZTM5YTU3ZjMwZDM=%7C1402e540eb537cd69f2ec4b61034c804b26bd8076ad372d5a6dc70f3ff4955f4', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 09:43:28] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 09:53:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.0.1654216677.0;%20username-localhost-8889=2%7C1:0%7C10:1654217624%7C23:username-localhost-8889%7C44:NmY4NWRmMzM4YzI1NDY1YzljNTk3ZmIyYjBiODJmYTk=%7C748fb8ff0280baabfb468b04d7c87791fb5b095da1d1ace2e8f989348db1469a', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 09:53:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 09:54:35] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='[{"name":"a","type":"int","value":"12"}]\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654217675%7C23:username-localhost-8889%7C44:ZDllZjY0MjRiN2I2NGZlNGI4ZGJhYzcxNGQ4MDY4Mjk=%7C4a41b785d3dedbc687c40dec37b5fd811e105b0ef6e86211641fa7531bb4d4ea', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d', no_reply=True)
[2022-06-03 09:54:36] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654217675%7C23:username-localhost-8889%7C44:N2FiZjRlODJkNGE2NGNmNGI3NGExMjQ1Y2FhMGExYjE=%7Cf613ab01ced89de6b5ce3c82e9eabfba944dd986fb07c872afc444a322773f16', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 09:54:36] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:01:50] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218109%7C23:username-localhost-8889%7C44:ODg5ZTIxMmY3N2Q1NGIwNmExYTZkNmM4YWNiOGIwNjI=%7C6dcfbbed0649098f888996b4790e839f78b4cec027ccf4e05e541bd420fb7de5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:01:50] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:04:19] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218257%7C23:username-localhost-8889%7C44:YzNlNmI4NjY3ZmI1NGQ3MGE1MTM1NWVhMTdhNmEyNjM=%7C31fd3101886fb6ff7a66fc52d298d4c4c05e5c954260918cdc9c3af06b155b87', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:04:19] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:04:25] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218265%7C23:username-localhost-8889%7C44:NjIzNTNiZjFiOTA5NDU3YjhiYTI5ZmNjYWYyMjMwNzY=%7C5bb20547f1a3ff2fc4e019edd5fe1f71f05c5e780ad083203d2e580381ae4ad5', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:04:25] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:04:26] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218265%7C23:username-localhost-8889%7C44:MzU3MzE0ZTE5OGU0NDM2Yzk2ZWFlOTdmY2I5Yjg4Y2I=%7C94d60e6eb3aa1e43206b647f893c0f7557bb9211c229e90c7ce1f88cd33fc241', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:04:26] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:04:33] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218273%7C23:username-localhost-8889%7C44:N2Y5OTEyNzlhYzg3NGNmYWI0ZWRjZjM0MTgwZDY3OTc=%7Ccf88f205448abec90abfe6992e578b98e4425654220022c40da747fa3fc64586', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:04:33] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:04:35] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218275%7C23:username-localhost-8889%7C44:NDgwMDc0NTkxZjIzNDA2NGJhZmI5M2E2YzAzMDYwZmY=%7C1c4e6da49ab8e2bfb923046035d42ace0e9d9be3ca1be4ce61db4aed7651818e', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:04:35] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:08:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218524%7C23:username-localhost-8889%7C44:ZDQ2MDNlMWE5MmY4NDM3MTkxNjE5ZjQ2YWQyZjlkMWM=%7Cfc1070fb261fc883e1f9505908c7d3111dc5840af3118cb4b50ad874e884862d', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:08:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:08:47] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218526%7C23:username-localhost-8889%7C44:Nzc2NmMyMzg2YjY4NDk4Y2I4NzExNzVhNzIxMDY1N2E=%7Cc3342a96900b33addd1fed8d65d630f778898808c7885d299893ff55da8ed4ec', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:08:47] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:15:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218914%7C23:username-localhost-8889%7C44:OWQxZjNkM2E3ZTM3NDYzNmExMzA2NzUxZmIwNzIyMjQ=%7C55c0779392c27ddcde4c1bd0d00721cff068ae65d67a89c7856ca07b2cb372ea', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:15:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:15:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654217675.0;%20username-localhost-8889=2%7C1:0%7C10:1654218918%7C23:username-localhost-8889%7C44:NjY1NmRmY2I2MzUyNDdkYTk1MDVhZGMzYzA0NGVlNzk=%7C9ef271859562fdd2f8d5c1e2621db08e6c51eb167ff91c0e5a04713fc2e63ee4', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:15:18] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:16:12] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654218971%7C23:username-localhost-8889%7C44:ZTYzM2RkMjE2ZmI4NGNhMjg3Y2E4NWYxYmVkNWEyMWU=%7C71dab545f0cf28ec4fc98c8c9ba2f2e0b98d16079339981b3af206f870f7e490', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:16:12] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:25:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654219544%7C23:username-localhost-8889%7C44:ZjhlNWZhNmE1NmI5NGZiMzgxYTI4MTM1NzVmNjgyOTU=%7C53a355a999e6fe5ca71c3ab5a47779ab2ad67e50a9d9fb84574a080e43bdff3b', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:25:45] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:28:59] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654219739%7C23:username-localhost-8889%7C44:OWZjZTUwYTY3Yjk2NDE4OWFiYjk0MmU4NTI5ODQwNmQ=%7C89873700d07ef5e85b62108e7996c9853fe5e98e48036888fef4f10c704a45ab', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:28:59] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:29:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654219740%7C23:username-localhost-8889%7C44:OTBjYWVmYWQ2ZjA0NDhlZTg2NzI2MWIzMzk0ODFiNzk=%7C52acea2552438f29a6ab29bcf2508f4be74c9bc281b1439c00735de7fb83bf9b', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:29:01] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:40:50] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654220448%7C23:username-localhost-8889%7C44:MDhlYzZhODAwZWY4NDg1ZmE5ODc5N2EzNzVlNmUzNGE=%7C7ec4e545e15042ca4d003fe67f5f45dad5529e0ee48fb41df668d81ee65a763a', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:40:50] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:40:54] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654220452%7C23:username-localhost-8889%7C44:YmUzODhhNGM3MmIzNDhjNzhmY2Q4YjZhYTg3YTFiZmU=%7C297827fd6798ed08446f5b4ea5e6a0e046dd03f41bcabbf0b1be37e9643a591f', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:40:54] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:41:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654220460%7C23:username-localhost-8889%7C44:NWRiMDMyMzYzYzgyNDEwYTkzNmZiNWYzNGZjOWJlOWQ=%7C9d6e5d8af613eaf55f9e8809a1e255993c61c91ee90d383cef0fd1bfbc4e933d', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:41:02] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:41:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654220500%7C23:username-localhost-8889%7C44:ODU3OWE2YTE1OWQyNDE1OGFiMzllZmRkZWQyOTVkYmY=%7C0e441feb9a3242cd8758991b88e2ef74044eb2b389b2b629957e541e94d94266', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:41:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-06-03 10:41:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8889/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20_xsrf=2%7C2da5b145%7C790fb5950d436be673db5541639d5799%7C1653959326;%20_ga=GA1.1.1429428078.1653959337;%20username-localhost-8888=2%7C1:0%7C10:1654160646%7C23:username-localhost-8888%7C44:NTliMTlkYTE4MDEzNDU5YmFiYjNhZTQ5NGE4NmMxZTg=%7Cc2053e0f9294fac3a34f1737fb87c6444cdf5d891413ac5e7af97ebe2160dfd9;%20_ga_R3VN4GNEX2=GS1.1.1654216650.2.0.1654216650.0;%20_ga_PQWQV19ZLY=GS1.1.1654216677.7.1.1654218939.0;%20username-localhost-8889=2%7C1:0%7C10:1654220504%7C23:username-localhost-8889%7C44:NmIyY2ExZTBmMTVjNDAzMGFjNjVjOTIwMWVjOTAwNzc=%7C909fdd9d4c18bc36e9cb9dbe45d663886632559c3a0c396a495449ca4fe2fbaa', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8889;%20Authorization=token%204c63912ac9dc2de14b07294cd748a63cbb5a0008cbafad3d')
[2022-06-03 10:41:44] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
