[2022-05-20 14:46:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"Load iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20username-localhost-8888=2%7C1:0%7C10:1653025575%7C23:username-localhost-8888%7C44:OGI5NDFjNTEyNjJiNDQ2MzhiNTdkNjZiNjAzNzhkMjI=%7C2c2c314c4327c24190c4cb3dadf0fcd2521d341a026905930d6a39a73e966704', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:46:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'Load iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:46:16] mrx-link.MRXLinkMagics.mrxlink_set_parameters() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='[{"name":"a","type":"int","value":"12"}]\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20username-localhost-8888=2%7C1:0%7C10:1653025575%7C23:username-localhost-8888%7C44:ZWFkYzY4YTQ3MWNkNGNmOGE0NzRlMWQxMGUwNzc0YWE=%7C1e07ab94262366b0d0a60318a1e1ad3d5e74a5ee8258e3b470819e07411b8111', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253', no_reply=True)
[2022-05-20 14:46:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"Load iris data","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025511.0;%20username-localhost-8888=2%7C1:0%7C10:1653025576%7C23:username-localhost-8888%7C44:NjY4OGU4MDc0OTEyNDhkY2IwZTdlMWZiNDk1YWJhNzA=%7C3f2c96fc96cf602af3c2bddb32e80935eb28a555bbcca5ca720831821a27f0ed', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:46:16] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': 'Load iris data', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:46:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025593.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025593.0;%20username-localhost-8888=2%7C1:0%7C10:1653025595%7C23:username-localhost-8888%7C44:NTBmN2RhMjIxNGJmNGJiOWEzYmJmNjQzOGEwZDc2MTU=%7C8a99ed77218e9cb5106a4a4f1a868b05ce215ba212bd26142c3a639c8f1558c7', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:46:37] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:46:37] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component Load iris data (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 123 (eef2dc4b-fb13-419b-a5af-f0031467c624)
[2022-05-20 14:46:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025593.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025593.0;%20username-localhost-8888=2%7C1:0%7C10:1653025600%7C23:username-localhost-8888%7C44:ZjkwNmU1NmI2ZmUwNDZiODhkOGJkMDlhY2U1OGE3Zjg=%7C4bdaaacd00748675735c02b933d990edbf4794feab746c2c9cc96254971f15fb', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:46:41] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:47:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: args: Namespace(base_url='http://localhost:8888/', cell='{"nodes":[{"id":"eef2dc4b-fb13-419b-a5af-f0031467c624","name":"123456","code":"from sklearn.datasets import load_iris\\n\\ndata = load_iris()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"cc60d6b2-ac7b-4963-860e-15753f04026f","name":"Create dataframe","code":"import numpy as np\\nimport pandas as pd\\n\\ndf = pd.DataFrame(data[\\"data\\"], columns=data[\\"feature_names\\"])\\ndf[\\"target\\"] = data[\\"target\\"]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","name":"Train valid split","code":"import numpy as np\\n\\ntrain_ratio = 0.7\\ntrain_len = int(train_ratio * len(df))\\nindices = np.random.permutation(df.index)\\ntrain_indices = indices[:train_len]\\nvalid_indices = indices[train_len:]","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"90b151b8-5c3d-48a2-b145-cf20d413d411","name":"Create dataloaders","code":"import torch\\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\\n\\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data[\\"feature_names\\"]].values).float(), torch.from_numpy(df.loc[:, \\"target\\"].values).long())\\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"c68dd5c0-4948-447f-83a5-51fd8856d231","name":"Define pl model","code":"from typing import Union, Dict, List, Any\\nimport torch\\nimport torchmetrics\\nimport pytorch_lightning as pl\\n\\nclass Classifier(pl.LightningModule):\\n    \\n    def __init__(self):\\n        super().__init__()\\n\\n        self._metrics: Dict[str, Dict[str, Any]] = {\\n            \\"train\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n            \\"valid\\": {\\n                \\"acc\\": torchmetrics.Accuracy(),\\n            },\\n        }\\n        seq = [\\n            torch.nn.Linear(4, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 8),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(8, 5),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(5, 3),\\n            torch.nn.Softmax(),\\n        ]\\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\\n\\n    def forward(self, x: torch.Tensor) -> Any:\\n        \\"\\"\\"\\n        Documentation.\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n        Returns\\n        -------\\n        Any\\n        \\"\\"\\"\\n        return self.fcn(x)\\n\\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\\n        batch_x, batch_y = train_batch\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"train_loss\\", loss, on_epoch=True)\\n\\n        train_metrics: List[Dict[str, Any]] = self._metrics[\\"train\\"]\\n        for name, metric in train_metrics.items():\\n            self.log(\\"Train: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n        return loss\\n\\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\\n        batch_x, batch_y = valid_batch\\n\\n        batch_y_hat: torch.Tensor = self(batch_x)\\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\\n        self.log(\\"valid_loss\\", loss, on_epoch=True)\\n        for name, metric in self._metrics[\\"valid\\"].items():\\n            self.log(\\"Valid: {0}\\".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\\n\\n    def configure_optimizers(self) -> Any:\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n        return optimizer","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","name":"Create pl model","code":"model = Classifier()","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","name":"Define liveplot logger","code":"import argparse\\nfrom typing import Any, Dict, Optional\\nfrom livelossplot import PlotLosses\\nfrom pytorch_lightning.loggers import LightningLoggerBase\\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\\nfrom pytorch_lightning.utilities import rank_zero_only, types\\n\\n\\nclass PlotLossesLogger(LightningLoggerBase):\\n    \\"\\"\\"Canvas Logger for lightning trainers\\n    Args:\\n        LightningLoggerBase ([type]): [description]\\n    \\"\\"\\"\\n\\n    def __init__(self, experiment=\\"tmp\\", max_epoch=None, **kwargs):\\n        super().__init__()\\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\\n        self._experiment = experiment\\n        self._last_epoch = 0\\n        self._last_metrics = {}\\n\\n    @property  # type: ignore\\n    @rank_zero_experiment\\n    def experiment(self) -> str:\\n        return self._experiment\\n\\n    @rank_zero_only\\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\\n        pass\\n\\n    @rank_zero_only\\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\\n        if metrics[\\"epoch\\"] > self._last_epoch:\\n            # Update accumulated metrics\\n            if \\"train_loss_step\\" in self._last_metrics:\\n                self._last_metrics.pop(\\"train_loss_step\\")\\n            self._plotlosses.update(self._last_metrics)\\n            self._plotlosses.send()\\n            self._last_epoch = metrics.pop(\\"epoch\\")\\n            self._last_metrics = metrics\\n        else:\\n            metrics.pop(\\"epoch\\")\\n            self._last_metrics = {**self._last_metrics, **metrics}\\n\\n    @property\\n    def name(self) -> str:\\n        return \\"canvas\\"\\n\\n    @property\\n    def version(self) -> str:\\n        return \\"prototype\\"","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"e5873610-eae0-44bb-9afe-c6a998def201","name":"Train model","code":"max_epoch = 10\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}},{"id":"a35aa072-1a5b-4e18-90b9-5877714bd0e0","name":"Retrain model","code":"max_epoch = 50\\nlogger = PlotLossesLogger(\\n    groups={\\"loss\\": [\\"train_loss_epoch\\", \\"valid_loss\\"], \\"Accuracy\\": [\\"Train: acc_epoch\\", \\"Valid: acc\\"]},\\n    max_epoch=max_epoch,\\n)\\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"componentType":"CodeCell","headerColor":"none","comments":[]}}],"edges":[{"parent":"eef2dc4b-fb13-419b-a5af-f0031467c624","child":"cc60d6b2-ac7b-4963-860e-15753f04026f"},{"parent":"cc60d6b2-ac7b-4963-860e-15753f04026f","child":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e"},{"parent":"99e0b9ab-ef73-4805-8628-8ef0e9811e5e","child":"90b151b8-5c3d-48a2-b145-cf20d413d411"},{"parent":"c68dd5c0-4948-447f-83a5-51fd8856d231","child":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728"},{"parent":"ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"4499176e-1f68-4dcb-b4d3-b9271c143e3a","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"90b151b8-5c3d-48a2-b145-cf20d413d411","child":"e5873610-eae0-44bb-9afe-c6a998def201"},{"parent":"e5873610-eae0-44bb-9afe-c6a998def201","child":"a35aa072-1a5b-4e18-90b9-5877714bd0e0"}]}\n', cookie='_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20_xsrf=2%7C718043cb%7C30bfcddb5af907ec50c0fb63efadbdca%7C1652858534;%20_ga=GA1.1.759674714.1652858538;%20_ga_R3VN4GNEX2=GS1.1.1652923635.3.0.1652923635.0;%20_ga_PQWQV19ZLY=GS1.1.1653024894.5.1.1653025620.0;%20username-localhost-8888=2%7C1:0%7C10:1653025622%7C23:username-localhost-8888%7C44:Y2MxOWVkNDFkODY0NDBjN2EzZGZkNzk3MGVkNmI2OWQ=%7C713084cb39b40c298c0ae244216e299cb4e6c603c62de735e19f4270de094423', header='Accept-Encoding=gzip,%20deflate,%20br;Host=localhost:8888;%20Authorization=token%2021dd363097a0b699c26857b8bdfbd72961b1128722cad253')
[2022-05-20 14:47:03] mrx-link.MRXLinkMagics.mrxlink_update_dag() DEBUG: graph: {'nodes': [{'id': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'name': '123456', 'code': 'from sklearn.datasets import load_iris\n\ndata = load_iris()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'name': 'Create dataframe', 'code': 'import numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(data["data"], columns=data["feature_names"])\ndf["target"] = data["target"]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'name': 'Train valid split', 'code': 'import numpy as np\n\ntrain_ratio = 0.7\ntrain_len = int(train_ratio * len(df))\nindices = np.random.permutation(df.index)\ntrain_indices = indices[:train_len]\nvalid_indices = indices[train_len:]', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'name': 'Create dataloaders', 'code': 'import torch\nfrom torch.utils.data import DataLoader, TensorDataset, Subset\n\ndataset = TensorDataset(torch.from_numpy(df.loc[:, data["feature_names"]].values).float(), torch.from_numpy(df.loc[:, "target"].values).long())\ntrain_loader = DataLoader(Subset(dataset, train_indices), batch_size=20)\nvalid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=len(valid_indices))', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'name': 'Define pl model', 'code': 'from typing import Union, Dict, List, Any\nimport torch\nimport torchmetrics\nimport pytorch_lightning as pl\n\nclass Classifier(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n\n        self._metrics: Dict[str, Dict[str, Any]] = {\n            "train": {\n                "acc": torchmetrics.Accuracy(),\n            },\n            "valid": {\n                "acc": torchmetrics.Accuracy(),\n            },\n        }\n        seq = [\n            torch.nn.Linear(4, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 5),\n            torch.nn.ReLU(),\n            torch.nn.Linear(5, 3),\n            torch.nn.Softmax(),\n        ]\n        self.fcn: torch.nn.Sequential = torch.nn.Sequential(*seq)\n\n    def forward(self, x: torch.Tensor) -> Any:\n        """\n        Documentation.\n        Parameters\n        ----------\n        x: torch.Tensor\n        Returns\n        -------\n        Any\n        """\n        return self.fcn(x)\n\n    def training_step(self, train_batch: torch.Tensor, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:\n        batch_x, batch_y = train_batch\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("train_loss", loss, on_epoch=True)\n\n        train_metrics: List[Dict[str, Any]] = self._metrics["train"]\n        for name, metric in train_metrics.items():\n            self.log("Train: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n        return loss\n\n    def validation_step(self, valid_batch: torch.Tensor, batch_idx: int) -> None:\n        batch_x, batch_y = valid_batch\n\n        batch_y_hat: torch.Tensor = self(batch_x)\n        loss = torch.nn.CrossEntropyLoss()(batch_y_hat, batch_y)\n        self.log("valid_loss", loss, on_epoch=True)\n        for name, metric in self._metrics["valid"].items():\n            self.log("Valid: {0}".format(name), metric(torch.argmax(batch_y_hat, dim=1), batch_y), on_epoch=True)\n\n    def configure_optimizers(self) -> Any:\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'name': 'Create pl model', 'code': 'model = Classifier()', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'name': 'Define liveplot logger', 'code': 'import argparse\nfrom typing import Any, Dict, Optional\nfrom livelossplot import PlotLosses\nfrom pytorch_lightning.loggers import LightningLoggerBase\nfrom pytorch_lightning.loggers.base import rank_zero_experiment\nfrom pytorch_lightning.utilities import rank_zero_only, types\n\n\nclass PlotLossesLogger(LightningLoggerBase):\n    """Canvas Logger for lightning trainers\n    Args:\n        LightningLoggerBase ([type]): [description]\n    """\n\n    def __init__(self, experiment="tmp", max_epoch=None, **kwargs):\n        super().__init__()\n        self._plotlosses = PlotLosses(**kwargs).reset_outputs().to_matplotlib(max_epoch=max_epoch)\n        self._experiment = experiment\n        self._last_epoch = 0\n        self._last_metrics = {}\n\n    @property  # type: ignore\n    @rank_zero_experiment\n    def experiment(self) -> str:\n        return self._experiment\n\n    @rank_zero_only\n    def log_hyperparams(self, params: argparse.Namespace, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    @rank_zero_only\n    def log_metrics(self, metrics: Dict[str, Any], step: Optional[int] = None) -> None:\n        if metrics["epoch"] > self._last_epoch:\n            # Update accumulated metrics\n            if "train_loss_step" in self._last_metrics:\n                self._last_metrics.pop("train_loss_step")\n            self._plotlosses.update(self._last_metrics)\n            self._plotlosses.send()\n            self._last_epoch = metrics.pop("epoch")\n            self._last_metrics = metrics\n        else:\n            metrics.pop("epoch")\n            self._last_metrics = {**self._last_metrics, **metrics}\n\n    @property\n    def name(self) -> str:\n        return "canvas"\n\n    @property\n    def version(self) -> str:\n        return "prototype"', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'e5873610-eae0-44bb-9afe-c6a998def201', 'name': 'Train model', 'code': 'max_epoch = 10\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}, {'id': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0', 'name': 'Retrain model', 'code': 'max_epoch = 50\nlogger = PlotLossesLogger(\n    groups={"loss": ["train_loss_epoch", "valid_loss"], "Accuracy": ["Train: acc_epoch", "Valid: acc"]},\n    max_epoch=max_epoch,\n)\ntrainer = pl.Trainer(max_epochs=max_epoch, logger=[logger], progress_bar_refresh_rate=0)\ntrainer.fit(model, train_loader, valid_loader)', 'metadata': {'componentType': 'CodeCell', 'headerColor': 'none', 'comments': []}}], 'edges': [{'parent': 'eef2dc4b-fb13-419b-a5af-f0031467c624', 'child': 'cc60d6b2-ac7b-4963-860e-15753f04026f'}, {'parent': 'cc60d6b2-ac7b-4963-860e-15753f04026f', 'child': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e'}, {'parent': '99e0b9ab-ef73-4805-8628-8ef0e9811e5e', 'child': '90b151b8-5c3d-48a2-b145-cf20d413d411'}, {'parent': 'c68dd5c0-4948-447f-83a5-51fd8856d231', 'child': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728'}, {'parent': 'ccee2dd0-8ca1-49b1-aa96-aeb3a9cca728', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '4499176e-1f68-4dcb-b4d3-b9271c143e3a', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': '90b151b8-5c3d-48a2-b145-cf20d413d411', 'child': 'e5873610-eae0-44bb-9afe-c6a998def201'}, {'parent': 'e5873610-eae0-44bb-9afe-c6a998def201', 'child': 'a35aa072-1a5b-4e18-90b9-5877714bd0e0'}]}
[2022-05-20 14:47:03] mrx-link.MRXLinkComponentCodeCell.mrxlink_update_dag() DEBUG: Component 123 (eef2dc4b-fb13-419b-a5af-f0031467c624) -> 123456 (eef2dc4b-fb13-419b-a5af-f0031467c624)
